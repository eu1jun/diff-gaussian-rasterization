{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b45871fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from plyfile import PlyData\n",
    "import matplotlib.pyplot as plt\n",
    "from diff_gaussian_rasterization import rasterize_gaussians, GaussianRasterizationSettings\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd022307",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# 1. PLY 파일 로드 및 데이터 추출\n",
    "ply_path = 'gs_data/syntactic.ply'\n",
    "plydata = PlyData.read(ply_path)\n",
    "vertex_data = plydata['vertex']\n",
    "num_points = len(vertex_data['x'])  # x 좌표의 개수를 이용하여 포인트 수 추정\n",
    "\n",
    "def prepare_sh_coefficients(vertex_data):\n",
    "    # 각 포인트당 SH 계수의 개수\n",
    "    sh_coeffs_per_point = 3 + 45  # f_dc 3개, f_rest 45개\n",
    "\n",
    "    # 결과를 저장할 numpy 배열 생성\n",
    "    shs = np.zeros(num_points * sh_coeffs_per_point, dtype=np.float32)\n",
    "\n",
    "    # f_dc와 f_rest를 shs 벡터에 복사\n",
    "    for i in range(num_points):\n",
    "        # f_dc 복사\n",
    "        shs[i * sh_coeffs_per_point + 0] = vertex_data['f_dc_0'][i]\n",
    "        shs[i * sh_coeffs_per_point + 1] = vertex_data['f_dc_1'][i]\n",
    "        shs[i * sh_coeffs_per_point + 2] = vertex_data['f_dc_2'][i]\n",
    "\n",
    "        # f_rest 복사\n",
    "        for j in range(45):\n",
    "            shs[i * sh_coeffs_per_point + 3 + j] = vertex_data[f'f_rest_{j}'][i]\n",
    "    return shs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36cd4f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. 속성 추출\n",
    "vertices = np.stack([vertex_data['x'], vertex_data['y'], vertex_data['z']], axis=-1)\n",
    "normals = np.stack([vertex_data['nx'], vertex_data['ny'], vertex_data['nz']], axis=-1)\n",
    "\n",
    "# 데이터 개수 확인\n",
    "# f_dc = np.stack([vertex_data['f_dc_0'], vertex_data['f_dc_1'], vertex_data['f_dc_2']], axis=-1)\n",
    "# f_rest = np.stack([vertex_data[f'f_rest_{i}'] for i in range(45)], axis=-1)\n",
    "\n",
    "shs = prepare_sh_coefficients(vertex_data)\n",
    "\n",
    "opacity = vertex_data['opacity']\n",
    "scales = np.stack([vertex_data['scale_0'], vertex_data['scale_1'], vertex_data['scale_2']], axis=-1)\n",
    "rotations = np.stack([\n",
    "    vertex_data['rot_0'],\n",
    "    vertex_data['rot_1'],\n",
    "    vertex_data['rot_2'],\n",
    "    vertex_data['rot_3']\n",
    "], axis=-1)\n",
    "\n",
    "# 3. PyTorch 텐서로 변환 및 GPU로 이동\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "means3D = torch.tensor(vertices, dtype=torch.float32).to(device)\n",
    "normals_tensor = torch.tensor(normals, dtype=torch.float32).to(device)\n",
    "opacity_tensor = torch.tensor(opacity, dtype=torch.float32).to(device)\n",
    "scales_tensor = torch.tensor(scales, dtype=torch.float32).to(device)\n",
    "rotations_tensor = torch.tensor(rotations, dtype=torch.float32).to(device)\n",
    "\n",
    "def compute_camera_matrices():\n",
    "    cam_pos = torch.tensor([0.0, 0.0, 5.0], dtype=torch.float32)\n",
    "    target = torch.tensor([0.0, 0.0, 0.0], dtype=torch.float32)\n",
    "    up = torch.tensor([0.0, 1.0, 0.0], dtype=torch.float32)\n",
    "\n",
    "    # 방향 벡터 계산\n",
    "    z_axis = F.normalize(cam_pos - target, dim=0)\n",
    "    x_axis = F.normalize(torch.cross(up, z_axis), dim=0)\n",
    "    y_axis = torch.cross(z_axis, x_axis)\n",
    "\n",
    "    # 뷰 매트릭스\n",
    "    view_matrix = torch.eye(4)\n",
    "    view_matrix[:3, :3] = torch.stack([x_axis, y_axis, z_axis])\n",
    "    view_matrix[:3, 3] = -torch.matmul(view_matrix[:3, :3], cam_pos)\n",
    "\n",
    "    # 투영 매트릭스\n",
    "    fov = 70.0\n",
    "    aspect_ratio = 800 / 600\n",
    "    near = 0.01\n",
    "    far = 100.0\n",
    "    proj_matrix = torch.zeros(4, 4)\n",
    "    fov_rad = torch.tensor(np.radians(fov / 2), dtype=torch.float32)  # Convert to radians and then to tensor\n",
    "    proj_matrix[0, 0] = 1 / (aspect_ratio * torch.tan(fov_rad))\n",
    "    proj_matrix[1, 1] = 1 / torch.tan(fov_rad)\n",
    "    proj_matrix[2, 2] = -(far + near) / (far - near)\n",
    "    proj_matrix[2, 3] = -(2 * far * near) / (far - near)\n",
    "    proj_matrix[3, 2] = -1\n",
    "\n",
    "    return view_matrix, proj_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c15eba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. 래스터화 설정 정의\n",
    "image_width = 800\n",
    "image_height = 600\n",
    "\n",
    "# 시야각 설정\n",
    "tan_fovx = np.tan(np.radians(70))\n",
    "tan_fovy = np.tan(np.radians(70))\n",
    "\n",
    "# 카메라 매트릭스 설정\n",
    "view_matrix, proj_matrix = compute_camera_matrices()\n",
    "\n",
    "# 배경 색상 설정 (검정색)\n",
    "background = torch.zeros(3, dtype=torch.float32).to(device)\n",
    "\n",
    "degree = 3  # SH 차수\n",
    "\n",
    "# 카메라 위치 설정\n",
    "campos = torch.tensor([0.0, 0.0, 5.0], dtype=torch.float32).to(device)\n",
    "\n",
    "# 래스터화 설정 객체 생성\n",
    "raster_settings = GaussianRasterizationSettings(\n",
    "    image_height=image_height,\n",
    "    image_width=image_width,\n",
    "    tanfovx=tan_fovx,\n",
    "    tanfovy=tan_fovy,\n",
    "    bg=background,\n",
    "    scale_modifier=1.0,\n",
    "    viewmatrix=view_matrix.contiguous().to(device),\n",
    "    projmatrix=proj_matrix.contiguous().to(device),\n",
    "    sh_degree=degree,\n",
    "    campos=campos.contiguous(),\n",
    "    prefiltered=False,\n",
    "    debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "705a38f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means3D shape: torch.Size([197984, 3])\n",
      "means2D shape: torch.Size([197984, 2])\n",
      "sh shape: torch.Size([197984, 48])\n",
      "colors_precomp shape: torch.Size([197984, 3])\n",
      "opacities shape: torch.Size([197984])\n",
      "scales shape: torch.Size([197984, 3])\n",
      "rotations shape: torch.Size([197984, 4])\n",
      "cov3Ds_precomp shape: torch.Size([197984, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "means2D = torch.zeros(size=(197984, 2), device=device, dtype=torch.float32)\n",
    "colors_precomp = torch.zeros((197984, 3), device=device, dtype=torch.float32)\n",
    "cov3Ds_precomp = torch.zeros((197984, 3, 3), device=device, dtype=torch.float32)\n",
    "shs = shs.reshape(num_points, 48)\n",
    "shs_tensor = torch.tensor(shs, dtype=torch.float32, device=device)\n",
    "print(\"means3D shape:\", means3D.shape)\n",
    "print(\"means2D shape:\", means2D.shape)\n",
    "print(\"sh shape:\", shs_tensor.shape)\n",
    "print(\"colors_precomp shape:\", colors_precomp.shape)\n",
    "print(\"opacities shape:\", opacity_tensor.shape)\n",
    "print(\"scales shape:\", scales_tensor.shape)\n",
    "print(\"rotations shape:\", rotations_tensor.shape)\n",
    "print(\"cov3Ds_precomp shape:\", cov3Ds_precomp.shape)\n",
    "\n",
    "color_image, radii = rasterize_gaussians(\n",
    "    means3D=means3D.to(device).contiguous(),\n",
    "    means2D=means2D.contiguous(),\n",
    "    sh=shs_tensor.contiguous(),  # (N, 48)\n",
    "    colors_precomp=colors_precomp.contiguous(), \n",
    "    opacities=opacity_tensor.to(device).contiguous(),\n",
    "    scales=scales_tensor.to(device).contiguous(),\n",
    "    rotations=rotations_tensor.to(device).contiguous(),\n",
    "    cov3Ds_precomp=cov3Ds_precomp.contiguous(),\n",
    "    raster_settings=raster_settings,\n",
    ")\n",
    "\n",
    "# 6. 결과 시각화\n",
    "color_image_cpu = color_image.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3812dac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "np.array(color_image_cpu).shape\n",
    "print(color_image_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c22682b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "color_image_cpu_transposed = np.transpose(color_image_cpu, (1, 2, 0))\n",
    "\n",
    "# Now we can display the image\n",
    "plt.imshow(color_image_cpu_transposed)\n",
    "plt.axis('off')  # Turns off the axis labels and ticks\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fee663",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ad_hynix] *",
   "language": "python",
   "name": "conda-env-.conda-ad_hynix-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
