{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b45871fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from plyfile import PlyData\n",
    "import matplotlib.pyplot as plt\n",
    "from diff_gaussian_rasterization import rasterize_gaussians, GaussianRasterizationSettings\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffdf5e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# big\n",
    "cam = {\n",
    "    \"id\": 0,\n",
    "    \"img_name\": \"_DSC8679\",\n",
    "    #\"width\": 4946,\n",
    "    \"width\": 800,\n",
    "    #\"height\": 3286,\n",
    "    \"height\": 600,\n",
    "    \"position\": [-3.0026817933840073, 1.4007726437615275, -2.2284005560263305],\n",
    "    \"rotation\": [\n",
    "        [0.6356840663395591, -0.03804422066319289, 0.7710112872559864],\n",
    "        [0.1589352827320079, 0.9838365806164537, -0.08249338484885187],\n",
    "        [-0.7554107119341767, 0.17498062725643193, 0.6314558071472982]\n",
    "    ],\n",
    "    \"fy\": 4627.300372546341,\n",
    "    \"fx\": 4649.505977743847\n",
    "}\n",
    "# small\n",
    "# cam = {\"id\": 0, \"img_name\": \"DSCF5565\", \"width\": 3118, \"height\": 2078, \"position\": [-3.7212285514226, 1.9830705231664232, -0.2941856450880261], \"rotation\": [[0.45692053375530706, -0.23930622827978038, 0.8567124108703402], [0.639268405842538, 0.7580520782954387, -0.12920120697387524], [-0.6185139700316442, 0.6067038616149328, 0.49935047128967736]], \"fy\": 3222.7010797592447, \"fx\": 3222.7010797592447}\n",
    "cam = {\"id\": 0, \"img_name\": \"DSCF5565\", \"width\": 800, \"height\": 600, \"position\": [-3.7212285514226, 1.9830705231664232, -0.2941856450880261], \"rotation\": [[0.45692053375530706, -0.23930622827978038, 0.8567124108703402], [0.639268405842538, 0.7580520782954387, -0.12920120697387524], [-0.6185139700316442, 0.6067038616149328, 0.49935047128967736]], \"fy\": 3222.7010797592447, \"fx\": 3222.7010797592447}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd022307",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1. PLY 파일 로드 및 데이터 추출\n",
    "ply_path = 'gs_data/point_cloud_small.ply'\n",
    "plydata = PlyData.read(ply_path)\n",
    "vertex_data = plydata['vertex']\n",
    "# vertex_data = vertex_data[:197984]\n",
    "num_points = len(vertex_data['x'])  # x 좌표의 개수를 이용하여 포인트 수 추정\n",
    "\n",
    "def prepare_sh_coefficients_vectorized(vertex_data, num_points):\n",
    "    sh_coeffs_per_point = 3 + 45  # f_dc 3개, f_rest 45개\n",
    "\n",
    "    # f_dc 계수 추출 및 스택\n",
    "    f_dc = np.stack([vertex_data[f'f_dc_{i}'] for i in range(3)], axis=-1)  # (num_points, 3)\n",
    "\n",
    "    # f_rest 계수 추출 및 스택\n",
    "    f_rest = np.stack([vertex_data[f'f_rest_{j}'] for j in range(45)], axis=-1)  # (num_points, 45)\n",
    "\n",
    "    # f_dc와 f_rest를 결합하여 최종 SH 계수 생성\n",
    "    shs = np.concatenate([f_dc, f_rest], axis=-1).astype(np.float32)  # (num_points, 48)\n",
    "\n",
    "    # 필요에 따라 1차원 배열로 평탄화\n",
    "    shs_flat = shs.reshape(-1)  # (num_points * 48,)\n",
    "\n",
    "    return shs_flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36cd4f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 속성 추출\n",
    "vertices = np.stack([vertex_data['x'], vertex_data['y'], vertex_data['z']], axis=-1)\n",
    "normals = np.stack([vertex_data['nx'], vertex_data['ny'], vertex_data['nz']], axis=-1)\n",
    "\n",
    "shs = prepare_sh_coefficients_vectorized(vertex_data, num_points)\n",
    "\n",
    "opacity = vertex_data['opacity']\n",
    "scales = np.stack([vertex_data['scale_0'], vertex_data['scale_1'], vertex_data['scale_2']], axis=-1)\n",
    "rotations = np.stack([\n",
    "    vertex_data['rot_0'],\n",
    "    vertex_data['rot_1'],\n",
    "    vertex_data['rot_2'],\n",
    "    vertex_data['rot_3']\n",
    "], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50bfdc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. PyTorch 텐서로 변환 및 GPU로 이동\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "means3D = torch.tensor(vertices, dtype=torch.float32).to(device)\n",
    "normals_tensor = torch.tensor(normals, dtype=torch.float32).to(device)\n",
    "opacity_tensor = torch.tensor(opacity, dtype=torch.float32).to(device)\n",
    "scales_tensor = torch.tensor(scales, dtype=torch.float32).to(device)\n",
    "rotations_tensor = torch.tensor(rotations, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60702448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_camera_matrices():\n",
    "    cam_pos = torch.tensor(cam[\"position\"], dtype=torch.float32)\n",
    "    rotation_matrix = torch.tensor(cam[\"rotation\"], dtype=torch.float32)  # 3x3 행렬\n",
    "    fx = cam[\"fx\"]\n",
    "    fy = cam[\"fy\"]\n",
    "    width = cam[\"width\"]\n",
    "    height = cam[\"height\"]\n",
    "\n",
    "    # 방향 벡터 계산\n",
    "    # 여기서 rotation_matrix는 월드 좌표계에서 카메라 좌표계로의 회전 행렬이라고 가정\n",
    "    # 보통 OpenGL과 DirectX는 카메라 매트릭스의 정의가 다를 수 있으니, 필요에 따라 수정\n",
    "    z_axis = F.normalize(cam_pos, dim=0)  # 카메라의 방향 벡터\n",
    "    x_axis = F.normalize(torch.cross(torch.tensor([0.0, 1.0, 0.0]), z_axis), dim=0)\n",
    "    y_axis = torch.cross(z_axis, x_axis)\n",
    "\n",
    "    # 뷰 매트릭스 생성\n",
    "    view_matrix = torch.eye(4, dtype=torch.float32)\n",
    "    view_matrix[:3, :3] = torch.stack([x_axis, y_axis, z_axis], dim=0)\n",
    "    view_matrix[:3, 3] = -torch.matmul(view_matrix[:3, :3], cam_pos)\n",
    "\n",
    "    # 투영 매트릭스 생성 (Intrinsic parameters 사용)\n",
    "    near = 0.01\n",
    "    far = 100.0\n",
    "    proj_matrix = torch.zeros(4, 4, dtype=torch.float32)\n",
    "    proj_matrix[0, 0] = 2 * fx / width\n",
    "    proj_matrix[1, 1] = 2 * fy / height\n",
    "    proj_matrix[2, 2] = -(far + near) / (far - near)\n",
    "    proj_matrix[2, 3] = -(2 * far * near) / (far - near)\n",
    "    proj_matrix[3, 2] = -1\n",
    "    return view_matrix, proj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c15eba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 래스터화 설정 정의\n",
    "image_width = 800\n",
    "image_height = 600\n",
    "\n",
    "# 시야각 설정\n",
    "tan_fovx = np.tan(np.radians(70))\n",
    "tan_fovy = np.tan(np.radians(70))\n",
    "\n",
    "# 카메라 매트릭스 설정\n",
    "view_matrix, proj_matrix = compute_camera_matrices()\n",
    "\n",
    "# 배경 색상 설정 (검정색)\n",
    "background = torch.zeros(3, dtype=torch.float32).to(device)\n",
    "\n",
    "degree = 3  # SH 차수\n",
    "\n",
    "# 카메라 위치 설정\n",
    "campos = torch.tensor([0.0, 0.0, 5.0], dtype=torch.float32).to(device)\n",
    "\n",
    "# 래스터화 설정 객체 생성\n",
    "raster_settings = GaussianRasterizationSettings(\n",
    "    image_height=image_height,\n",
    "    image_width=image_width,\n",
    "    tanfovx=tan_fovx,\n",
    "    tanfovy=tan_fovy,\n",
    "    bg=background,\n",
    "    scale_modifier=1.0,\n",
    "    viewmatrix=view_matrix.contiguous().to(device),\n",
    "    projmatrix=proj_matrix.contiguous().to(device),\n",
    "    sh_degree=degree,\n",
    "    campos=campos.contiguous(),\n",
    "    prefiltered=False,\n",
    "    debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "705a38f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means3D shape: torch.Size([1157141, 3])\n",
      "means2D shape: torch.Size([1157141, 2])\n",
      "sh shape: torch.Size([1157141, 48])\n",
      "colors_precomp shape: torch.Size([1157141, 3])\n",
      "opacities shape: torch.Size([1157141])\n",
      "scales shape: torch.Size([1157141, 3])\n",
      "rotations shape: torch.Size([1157141, 4])\n",
      "cov3Ds_precomp shape: torch.Size([1157141, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "means2D = torch.zeros(size=(num_points, 2), device=device, dtype=torch.float32)\n",
    "colors_precomp = torch.zeros((num_points, 3), device=device, dtype=torch.float32)\n",
    "cov3Ds_precomp = torch.zeros((num_points, 3, 3), device=device, dtype=torch.float32)\n",
    "shs = shs.reshape(num_points, 48)\n",
    "shs_tensor = torch.tensor(shs, dtype=torch.float32, device=device)\n",
    "print(\"means3D shape:\", means3D.shape)\n",
    "print(\"means2D shape:\", means2D.shape)\n",
    "print(\"sh shape:\", shs_tensor.shape)\n",
    "print(\"colors_precomp shape:\", colors_precomp.shape)\n",
    "print(\"opacities shape:\", opacity_tensor.shape)\n",
    "print(\"scales shape:\", scales_tensor.shape)\n",
    "print(\"rotations shape:\", rotations_tensor.shape)\n",
    "print(\"cov3Ds_precomp shape:\", cov3Ds_precomp.shape)\n",
    "\n",
    "color_image, radii = rasterize_gaussians(\n",
    "    means3D=means3D.to(device).contiguous(),\n",
    "    means2D=means2D.contiguous(),\n",
    "    sh=shs_tensor.contiguous(),  # (N, 48)\n",
    "    colors_precomp=colors_precomp.contiguous(), \n",
    "    opacities=opacity_tensor.to(device).contiguous(),\n",
    "    scales=scales_tensor.to(device).contiguous(),\n",
    "    rotations=rotations_tensor.to(device).contiguous(),\n",
    "    cov3Ds_precomp=cov3Ds_precomp.contiguous(),\n",
    "    raster_settings=raster_settings,\n",
    ")\n",
    "\n",
    "# 6. 결과 시각화\n",
    "color_image_cpu = color_image.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "baff97cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-4.1822376 -4.2493176 -4.1399226]\n",
      "  [-4.181668  -4.248859  -4.139349 ]\n",
      "  [-4.1810956 -4.2483997 -4.1387744]\n",
      "  ...\n",
      "  [-3.6440735 -3.7824528 -3.6028445]\n",
      "  [-3.6432986 -3.7817416 -3.6020749]\n",
      "  [-3.6425223 -3.7810287 -3.6013045]]\n",
      "\n",
      " [[-4.1818943 -4.2491264 -4.139565 ]\n",
      "  [-4.181322  -4.248666  -4.1389894]\n",
      "  [-4.180751  -4.248208  -4.1384153]\n",
      "  ...\n",
      "  [-3.6435206 -3.7820091 -3.6022804]\n",
      "  [-3.6427464 -3.7812974 -3.601512 ]\n",
      "  [-3.6419702 -3.7805855 -3.6007414]]\n",
      "\n",
      " [[-4.1815495 -4.248932  -4.139204 ]\n",
      "  [-4.180978  -4.248474  -4.1386294]\n",
      "  [-4.1804066 -4.248017  -4.138055 ]\n",
      "  ...\n",
      "  [-3.642968  -3.781565  -3.6017163]\n",
      "  [-3.642192  -3.7808523 -3.600946 ]\n",
      "  [-3.6414154 -3.7801385 -3.600175 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-3.9176652 -4.0693107 -3.8658402]\n",
      "  [-3.91693   -4.068657  -3.8651063]\n",
      "  [-3.916197  -4.0680013 -3.8643734]\n",
      "  ...\n",
      "  [-3.2545385 -3.444531  -3.20798  ]\n",
      "  [-3.2536247 -3.4436345 -3.2070765]\n",
      "  [-3.2527075 -3.442735  -3.2061708]]\n",
      "\n",
      " [[-3.9171178 -4.0688915 -3.8652775]\n",
      "  [-3.9163837 -4.0682354 -3.8645442]\n",
      "  [-3.91565   -4.0675807 -3.8638115]\n",
      "  ...\n",
      "  [-3.2537904 -3.4438434 -3.2072248]\n",
      "  [-3.2528756 -3.4429457 -3.2063208]\n",
      "  [-3.2519593 -3.442048  -3.205416 ]]\n",
      "\n",
      " [[-3.9165707 -4.0684686 -3.8647149]\n",
      "  [-3.9158366 -4.067814  -3.8639822]\n",
      "  [-3.915102  -4.0671577 -3.8632488]\n",
      "  ...\n",
      "  [-3.2530396 -3.4431531 -3.2064693]\n",
      "  [-3.2521255 -3.442258  -3.2055652]\n",
      "  [-3.2512095 -3.4413579 -3.20466  ]]]\n"
     ]
    }
   ],
   "source": [
    "color_image_cpu_transposed = np.transpose(color_image_cpu, (1, 2, 0))\n",
    "print(color_image_cpu_transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1349664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Now we can display the image\n",
    "plt.imshow(color_image_cpu_transposed)\n",
    "plt.axis('off')  # Turns off the axis labels and ticks\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73024316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ad_hynix] *",
   "language": "python",
   "name": "conda-env-.conda-ad_hynix-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
